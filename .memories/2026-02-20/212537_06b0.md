---
id: checkpoint_06b0c1af
timestamp: 2026-02-20T21:25:37.980Z
tags:
  - eros
  - mps
  - cpu
  - device
  - crash-fix
  - config
git:
  branch: main
  commit: ce7296a
  files:
    - .julie/.gitignore
    - .memories/.active-plan
    - .memories/2026-02-20/201733_a7d4.md
    - .memories/2026-02-20/202020_cc86.md
    - .memories/2026-02-20/202648_a806.md
    - .memories/2026-02-20/203512_da98.md
    - .memories/plans/add-file-logging-timing-instrumentation-to-eros.md
    - CLAUDE.md
    - python/eros/config.py
    - python/eros/embeddings.py
    - python/eros/retrieval.py
    - python/eros/server.py
    - python/tests/test_embeddings.py
    - python/tests/test_logging.py
    - python/tests/test_retrieval.py
summary: "## Switched default device from MPS to CPU"
---

## Switched default device from MPS to CPU

MPS was causing kernel panics on macOS when encoding 5500+ real code chunks (up to 4000 chars each). batch_size=128 with long tokenized sequences exhausted GPU memory on unified memory architecture, crashing the entire system.

- **Root cause:** MPS + large batches of long text chunks = unbounded GPU memory usage on Apple Silicon
- **Fix:** Default to CPU (`EROS_DEVICE=cpu`), added `EROS_DEVICE` env var for opt-in GPU use
- **Changes:**
  - `config.py`: Added `device` field (default "cpu", env var `EROS_DEVICE`)
  - `embeddings.py`: Split `detect_device()` into `_auto_detect_device()` + `resolve_device(configured)` 
  - `retrieval.py`: Reverted batch_size from 128 to 64 (better for CPU)
  - CLAUDE.md: Documented `EROS_DEVICE` env var
- **Tests:** 94 passing, lint clean
- **Impact:** No more system crashes. Users can opt into MPS/CUDA with `EROS_DEVICE=auto`
