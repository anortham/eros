---
id: checkpoint_cc866d6a
timestamp: 2026-02-20T20:20:20.839Z
tags:
  - eros
  - performance
  - mps
  - batch-size
  - indexing
git:
  branch: main
  commit: ce7296a
  files:
    - .julie/.gitignore
    - .memories/2026-02-20/201733_a7d4.md
    - python/eros/retrieval.py
summary: "## Fixed MPS batch size for indexing performance"
---

## Fixed MPS batch size for indexing performance

Indexing was slow despite MPS being available because batch_size=32 caused excessive CPU↔GPU round trips.

- **Root cause:** Default `batch_size=32` means ~173 batches for 5543 chunks — transfer overhead dominated
- **Benchmarks:** MPS is 0.7x (slower) at 100 texts, but 3.9x faster at 500+ texts with larger batches
- **Fix:** Bumped indexing batch_size to 128 in `retrieval.py` for both `embed_code` and `embed_docs`
- **Impact:** Indexing large reference workspaces should be significantly faster now
- **Tests:** All 80 tests pass
