---
id: checkpoint_4152e0a6
timestamp: 2026-02-25T02:22:07.999Z
tags:
  - eros
  - performance
  - adaptive-batching
  - embeddings
  - indexing
git:
  branch: main
  commit: ca188f4
  files:
    - .memories/2026-02-25/021020_01aa.md
    - .memories/2026-02-25/021910_f71c.md
    - python/eros/config.py
    - python/eros/embeddings.py
    - python/eros/incremental.py
    - python/eros/indexing.py
    - python/eros/julie_reader.py
    - python/eros/retrieval.py
    - python/eros/storage.py
    - python/tests/test_embeddings.py
    - python/tests/test_julie_reader.py
    - python/tests/test_retrieval.py
summary: "## Added adaptive batch sizing for embeddings and indexing"
planId: add-file-logging-timing-instrumentation-to-eros
type: checkpoint
confidence: 5
---

## Added adaptive batch sizing for embeddings and indexing

- **WHAT:** Implemented device-aware adaptive batch sizing and wired indexing to use it instead of hardcoded batch sizes.
- **WHY:** First-time/full indexing was still using fixed `batch_size=64`, which is suboptimal across CPU/MPS/CUDA and can be too slow (or too memory-heavy) depending on environment.
- **HOW:**
  - Added `adaptive_batch_size()` and device base map in `python/eros/embeddings.py`.
  - Added `DualEmbeddingManager.index_batch_size(scope, text_count)` and updated `embed_code` / `embed_docs` to accept optional batch size and auto-pick when omitted.
  - Updated query embedding paths to always use query batch size of 1.
  - Updated indexing in `python/eros/indexing.py` to request batch size from embeddings manager for both code and docs, removing hardcoded 64.
  - Expanded debug logging in `_ModelSlot.encode()` to include selected batch size.

### Tests
- Added adaptive batch sizing tests in `python/tests/test_embeddings.py`.
- Updated fake embeddings and added `test_index_uses_adaptive_batch_size` in `python/tests/test_retrieval.py`.

### Verification
- `uv run pytest -q --tb=short python/tests/test_embeddings.py python/tests/test_retrieval.py` → passed
- `uv run pytest -q --tb=short python/tests/` → **103 passed**
- `uv run ruff check python/eros python/tests` → passed

### Impact
- Indexing now scales batch size by device type and workload size.
- Better out-of-box throughput on GPU/MPS and safer memory behavior on CPU/smaller runs.

