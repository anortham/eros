---
id: checkpoint_ce2f01c8
timestamp: 2026-02-25T02:26:01.466Z
tags:
  - eros
  - performance
  - self-tuning
  - batch-size
  - embeddings
git:
  branch: main
  commit: ca188f4
  files:
    - .memories/2026-02-25/021020_01aa.md
    - .memories/2026-02-25/021910_f71c.md
    - .memories/2026-02-25/022207_4152.md
    - python/eros/config.py
    - python/eros/embeddings.py
    - python/eros/incremental.py
    - python/eros/indexing.py
    - python/eros/julie_reader.py
    - python/eros/retrieval.py
    - python/eros/storage.py
    - python/tests/test_embeddings.py
    - python/tests/test_julie_reader.py
    - python/tests/test_retrieval.py
summary: "## Added self-tuning embedding batch sizing"
planId: add-file-logging-timing-instrumentation-to-eros
type: checkpoint
confidence: 5
---

## Added self-tuning embedding batch sizing

- **WHAT:** Upgraded adaptive batching to runtime self-tuning behavior with OOM backoff and throughput-guided growth.
- **WHY:** Static per-device defaults were better than fixed `64` but still blunt; real workloads vary, so the embedding layer should adapt automatically.
- **HOW:**
  - Implemented tuning state in `python/eros/embeddings.py`:
    - `_BatchTuningState(batch_size, best_tps)` per scope (`code`, `docs`)
    - `_embed_with_autotune()` retry loop
    - `_is_oom_error()` detection + automatic batch halving on OOM
    - `_autotune_after_success()` to increase/decrease batch based on workload + throughput trend
  - Added device ceilings (`_INDEX_BATCH_MAX`) to avoid runaway batch growth.
  - `index_batch_size()` now reports tuned state rather than static base.
  - `embed_code()` / `embed_docs()` now default to self-tuned auto mode (explicit batch still supported).
  - Query embedding remains batch size 1.

### Tests
- Added `TestSelfTuningBatching` in `python/tests/test_embeddings.py`:
  - verifies OOM backoff path
  - verifies growth on successful large workload
- Existing retrieval/index tests continue to pass with tuned batching.

### Verification
- `uv run pytest -q --tb=short python/tests/test_embeddings.py python/tests/test_retrieval.py` → passed
- `uv run pytest -q --tb=short python/tests/` → **105 passed**
- `uv run ruff check python/eros python/tests` → passed

### Impact
- Batch size now adapts in-process to actual embedding behavior instead of staying fixed.
- Better throughput over time on capable devices and automatic survival when memory pressure hits.

